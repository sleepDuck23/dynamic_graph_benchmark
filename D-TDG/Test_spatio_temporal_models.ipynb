{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric_temporal\n",
        "!pip install -U torch-geometric  # or pip install torch-geometric --upgrade\n",
        "!sed -i 's/from torch_geometric.utils.to_dense_adj import to_dense_adj/from torch_geometric.utils.dense import to_dense_adj/' /usr/local/lib/python3.11/dist-packages/torch_geometric_temporal/nn/attention/tsagcn.py\n",
        "!sed -i 's/from torch_geometric.utils.dense import to_dense_adj/from torch_geometric.utils import to_dense_adj/' /usr/local/lib/python3.11/dist-packages/torch_geometric_temporal/nn/attention/tsagcn.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBeInWeMmQ5-",
        "outputId": "6023f965-cd2c-410f-9bf1-446d099c219b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric_temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.5.1+cu124)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.0.12)\n",
            "Collecting pandas<=1.3.5 (from torch_geometric_temporal)\n",
            "  Downloading pandas-1.3.5.tar.gz (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_sparse (from torch_geometric_temporal)\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_scatter (from torch_geometric_temporal)\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_geometric (from torch_geometric_temporal)\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.11/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch_geometric_temporal) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch_geometric_temporal) (3.11.12)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch_geometric_temporal) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch_geometric_temporal) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch_geometric_temporal) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch_geometric_temporal) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch_geometric_temporal) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch_geometric_temporal) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m791.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch_geometric_temporal, pandas, torch_scatter, torch_sparse\n",
            "  Building wheel for torch_geometric_temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric_temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86709 sha256=ba3072ade242331c0e96ad22a86eaa1f608ae56c9294e632915a95724f390c8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/e1/7e/241df4afecc89c69dece70c49a2d728b4926d9594683e31adb\n",
            "  Building wheel for pandas (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas: filename=pandas-1.3.5-cp311-cp311-linux_x86_64.whl size=37464040 sha256=e61e301d7c22941661010d97feda4c35e6f36e4af31200ddca70b245c1550112\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/e7/6d/d4c288f419ab8fa07c1db6f606a2ae18ecf3dc2839d79a1c07\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=545106 sha256=b2f75a0f9eda00e902832fbf6610a82b9f6eaec9846e63718161a9830bdbecce\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=1122943 sha256=9384d79cde4318028a8a486633512c1ba5967bb3daeedd30b04ae2af0750e0cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "Successfully built torch_geometric_temporal pandas torch_scatter torch_sparse\n",
            "Installing collected packages: torch_scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch_sparse, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12, torch_geometric_temporal\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.3.5 which is incompatible.\n",
            "arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "bigframes 1.36.0 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pandas-1.3.5 torch_geometric-2.6.1 torch_geometric_temporal-0.54.0 torch_scatter-2.1.2 torch_sparse-0.6.18\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVNpVhZlmRfw",
        "outputId": "2e4e5391-46e7-4765-bc3b-e56cc451e66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydgn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEktPDDqmTrR",
        "outputId": "8f491765-11c1-48ac-9f23-9bd8a05e67f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydgn\n",
            "  Downloading pydgn-1.6.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pydgn) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from pydgn) (4.67.1)\n",
            "Requirement already satisfied: Requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from pydgn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pydgn) (1.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.11.0 in /usr/local/lib/python3.11/dist-packages (from pydgn) (2.18.0)\n",
            "Collecting ogb>=1.2.0 (from pydgn)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting ray>=2.6.0 (from pydgn)\n",
            "  Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pydgn) (2.5.1+cu124)\n",
            "Requirement already satisfied: torch-geometric>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pydgn) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb>=1.2.0->pydgn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb>=1.2.0->pydgn) (1.3.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb>=1.2.0->pydgn) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb>=1.2.0->pydgn) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.2.0->pydgn)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (3.17.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (4.25.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.6.0->pydgn) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from Requests>=2.31.0->pydgn) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from Requests>=2.31.0->pydgn) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from Requests>=2.31.0->pydgn) (2025.1.31)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->pydgn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->pydgn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->pydgn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.11.0->pydgn) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->pydgn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->pydgn) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->pydgn) (3.11.12)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->pydgn) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->pydgn) (3.2.1)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.2.0->pydgn)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb>=1.2.0->pydgn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb>=1.2.0->pydgn) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.11.0->pydgn) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->pydgn) (2.4.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->pydgn) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->pydgn) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->pydgn) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->pydgn) (1.18.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.6.0->pydgn) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.6.0->pydgn) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.6.0->pydgn) (0.22.3)\n",
            "Downloading pydgn-1.6.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, outdated, ray, ogb, pydgn\n",
            "Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 pydgn-1.6.0 ray-2.42.1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade torch_geometric_temporal"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha1NwFkursBq",
        "outputId": "75335098-71d5-434d-d020-2dbd25b08235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric_temporal in /usr/local/lib/python3.11/dist-packages (0.54.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.5.1+cu124)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.0.12)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (1.3.5)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (0.6.18)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.1.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.11/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch_geometric_temporal) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (3.11.12)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch_geometric_temporal) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n"
      ],
      "metadata": {
        "id": "7UXYvg66wknW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class MontevideoBusDatasetLoader(object):\n",
        "    \"\"\"A dataset of inflow passenger at bus stop level from Montevideo city.\n",
        "    This dataset comprises hourly inflow passenger data at bus stop level for 11 bus lines during\n",
        "    October 2020 from Montevideo city (Uruguay). The bus lines selected are the ones that carry\n",
        "    people to the center of the city and they load more than 25% of the total daily inflow traffic.\n",
        "    Vertices are bus stops, edges are links between bus stops when a bus line connects them and the\n",
        "    weight represent the road distance. The target is the passenger inflow. This is a curated\n",
        "    dataset made from different data sources of the Metropolitan Transportation System (STM) of\n",
        "    Montevideo. These datasets are freely available to anyone in the National Catalog of Open Data\n",
        "    from the government of Uruguay (https://catalogodatos.gub.uy/).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._read_web_data()\n",
        "\n",
        "    def _read_web_data(self):\n",
        "        url = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/montevideo_bus.json\"\n",
        "        self._dataset = json.loads(urllib.request.urlopen(url).read())\n",
        "\n",
        "    def _get_node_ids(self):\n",
        "        return [node.get('bus_stop') for node in self._dataset[\"nodes\"]]\n",
        "\n",
        "    def _get_edges(self):\n",
        "        node_ids = self._get_node_ids()\n",
        "        node_id_map = dict(zip(node_ids, range(len(node_ids))))\n",
        "        self._edges = np.array(\n",
        "            [(node_id_map[d[\"source\"]], node_id_map[d[\"target\"]]) for d in self._dataset[\"links\"]]\n",
        "        ).T\n",
        "\n",
        "    def _get_edge_weights(self):\n",
        "        self._edge_weights = np.array([(d[\"weight\"]) for d in self._dataset[\"links\"]]).T\n",
        "\n",
        "    def _get_features(self, feature_vars: List[str] = [\"y\"]):\n",
        "        features = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            X = node.get(\"X\")\n",
        "            for feature_var in feature_vars:\n",
        "                features.append(np.array(X.get(feature_var)))\n",
        "        stacked_features = np.stack(features).T\n",
        "        standardized_features = (\n",
        "            stacked_features - np.mean(stacked_features, axis=0)\n",
        "        ) / np.std(stacked_features, axis=0)\n",
        "        self.features = [\n",
        "            standardized_features[i : i + self.lags, :].T\n",
        "            for i in range(len(standardized_features) - self.lags)\n",
        "        ]\n",
        "\n",
        "    def _get_targets(self, target_var: str = \"y\"):\n",
        "        targets = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            y = node.get(target_var)\n",
        "            targets.append(np.array(y))\n",
        "        stacked_targets = np.stack(targets).T\n",
        "        standardized_targets = (\n",
        "            stacked_targets - np.mean(stacked_targets, axis=0)\n",
        "        ) / np.std(stacked_targets, axis=0)\n",
        "        self.targets = [\n",
        "            standardized_targets[i + self.lags, :].T\n",
        "            for i in range(len(standardized_targets) - self.lags)\n",
        "        ]\n",
        "    def get_dataset(\n",
        "        self, lags: int = 4, target_var: str = \"y\", feature_vars: List[str] = [\"y\"]\n",
        "    ) -> StaticGraphTemporalSignal:\n",
        "        \"\"\"Returning the MontevideoBus passenger inflow data iterator.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        lags : int, optional\n",
        "            The number of time lags, by default 4.\n",
        "        target_var : str, optional\n",
        "            Target variable name, by default \"y\".\n",
        "        feature_vars : List[str], optional\n",
        "            List of feature variables, by default [\"y\"].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        StaticGraphTemporalSignal\n",
        "            The MontevideoBus dataset.\n",
        "        \"\"\"\n",
        "        self.lags = lags\n",
        "        self._get_edges()\n",
        "        self._get_edge_weights()\n",
        "        self._get_features(feature_vars)\n",
        "        self._get_targets(target_var)\n",
        "        dataset = StaticGraphTemporalSignal(\n",
        "            self._edges, self._edge_weights, self.features, self.targets\n",
        "        )\n",
        "        return dataset"
      ],
      "metadata": {
        "id": "2ZxcIEzvl_gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class A3TGCN(nn.Module):\n",
        "    \"\"\"\n",
        "    A3T-GCN model for spatio-temporal forecasting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(A3TGCN, self).__init__()\n",
        "        self.gcn = nn.Linear(input_dim, hidden_dim)  # Placeholder GCN layer\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=2)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gcn(x)\n",
        "        x, _ = self.attention(x, x, x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_dim = 16  # Placeholder value, replace with actual dataset feature size\n",
        "    model = A3TGCN(input_dim=input_dim, hidden_dim=64, output_dim=1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(\"A3T-GCN model initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLj7Vem_wYF6",
        "outputId": "48b4f5ff-cff0-46c4-fcfd-73d626fb44ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A3T-GCN model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from typing import List\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "\n",
        "class A3TGCN(nn.Module):\n",
        "    \"\"\"\n",
        "    A3T-GCN model for spatio-temporal forecasting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, num_nodes):\n",
        "        super(A3TGCN, self).__init__()\n",
        "        self.gcn = nn.Linear(input_dim, hidden_dim)  # Placeholder GCN layer\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=2, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)  # Ensure output matches num_nodes\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_nodes, num_features = x.shape\n",
        "\n",
        "        # Reshape for Linear Layer\n",
        "        x = x.view(-1, num_features)  # (batch_size * num_nodes, input_dim)\n",
        "\n",
        "        x = self.gcn(x)  # (batch_size * num_nodes, hidden_dim)\n",
        "\n",
        "        # Reshape back to (batch_size, num_nodes, hidden_dim)\n",
        "        x = x.view(batch_size, num_nodes, -1)\n",
        "\n",
        "        x, _ = self.attention(x, x, x)  # (batch_size, num_nodes, hidden_dim)\n",
        "\n",
        "        x = self.fc(x)  # (batch_size, num_nodes, 1)\n",
        "\n",
        "        return x.squeeze(-1)  # Final shape: (batch_size, num_nodes)\n",
        "\n",
        "class MontevideoBusDatasetLoader:\n",
        "    def __init__(self):\n",
        "        self._read_web_data()\n",
        "\n",
        "    def _read_web_data(self):\n",
        "        url = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/montevideo_bus.json\"\n",
        "        self._dataset = json.loads(urllib.request.urlopen(url).read())\n",
        "\n",
        "    def _get_node_ids(self):\n",
        "        return [node.get('bus_stop') for node in self._dataset[\"nodes\"]]\n",
        "\n",
        "    def _get_edges(self):\n",
        "        node_ids = self._get_node_ids()\n",
        "        node_id_map = dict(zip(node_ids, range(len(node_ids))))\n",
        "        self._edges = np.array(\n",
        "            [(node_id_map[d[\"source\"]], node_id_map[d[\"target\"]]) for d in self._dataset[\"links\"]]\n",
        "        ).T\n",
        "\n",
        "    def _get_edge_weights(self):\n",
        "        self._edge_weights = np.array([(d[\"weight\"]) for d in self._dataset[\"links\"]]).T\n",
        "\n",
        "    def _get_features(self, feature_vars: List[str] = [\"y\"]):\n",
        "        features = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            X = node.get(\"X\")\n",
        "            for feature_var in feature_vars:\n",
        "                features.append(np.array(X.get(feature_var)))\n",
        "        stacked_features = np.stack(features).T\n",
        "        standardized_features = (\n",
        "            stacked_features - np.mean(stacked_features, axis=0)\n",
        "        ) / np.std(stacked_features, axis=0)\n",
        "        self.features = [\n",
        "            standardized_features[i : i + self.lags, :].T\n",
        "            for i in range(len(stacked_features) - self.lags)\n",
        "        ]\n",
        "\n",
        "    def _get_targets(self, target_var: str = \"y\"):\n",
        "        targets = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            y = node.get(target_var)\n",
        "            targets.append(np.array(y))\n",
        "        stacked_targets = np.stack(targets).T\n",
        "        standardized_targets = (\n",
        "            stacked_targets - np.mean(stacked_targets, axis=0)\n",
        "        ) / np.std(stacked_targets, axis=0)\n",
        "        self.targets = [\n",
        "            standardized_targets[i + self.lags, :].T\n",
        "            for i in range(len(stacked_targets) - self.lags)\n",
        "        ]\n",
        "\n",
        "    def get_dataset(self, lags: int = 4, target_var: str = \"y\", feature_vars: List[str] = [\"y\"]):\n",
        "        self.lags = lags\n",
        "        self._get_edges()\n",
        "        self._get_edge_weights()\n",
        "        self._get_features(feature_vars)\n",
        "        self._get_targets(target_var)\n",
        "        dataset = StaticGraphTemporalSignal(\n",
        "            self._edges, self._edge_weights, self.features, self.targets\n",
        "        )\n",
        "        return dataset\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "def test_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            test_loss += loss.item()\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_loader = MontevideoBusDatasetLoader()\n",
        "    dataset = dataset_loader.get_dataset()\n",
        "\n",
        "    #input_dim = len(dataset.features[0])\n",
        "    print(\"Feature Shape:\", np.array(dataset.features).shape)\n",
        "    input_dim = dataset.features[0].shape[-1]  # Ensure correct input dimension\n",
        "    num_nodes = dataset.targets[0].shape[0]  # Ensure correct output size\n",
        "    print(\"Input Dimension:\", input_dim)\n",
        "    print(\"Number of Nodes:\", num_nodes)\n",
        "    model = A3TGCN(input_dim=input_dim, hidden_dim=64, num_nodes=num_nodes)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Convert dataset into tensors\n",
        "    X_tensor = torch.tensor(np.array(dataset.features), dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(np.array(dataset.targets), dtype=torch.float32)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    dataset_size = len(X_tensor)\n",
        "    train_size = int(0.8 * dataset_size)\n",
        "    test_size = dataset_size - train_size\n",
        "    train_dataset, test_dataset = random_split(TensorDataset(X_tensor, y_tensor), [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Train and test the model\n",
        "    train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "    test_model(model, test_loader, criterion)\n",
        "\n",
        "    print(\"A3T-GCN model training and testing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fRyqMoxxRhP",
        "outputId": "cceff6cd-33b4-4b3d-d474-6a66533b3835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Shape: (740, 675, 4)\n",
            "Input Dimension: 4\n",
            "Number of Nodes: 675\n",
            "Epoch 1, Loss: 0.9566035615770441\n",
            "Epoch 2, Loss: 0.913731386787013\n",
            "Epoch 3, Loss: 0.9207206337075484\n",
            "Epoch 4, Loss: 0.913191911421324\n",
            "Epoch 5, Loss: 0.9087845683097839\n",
            "Epoch 6, Loss: 0.9121853458253961\n",
            "Epoch 7, Loss: 0.921468624943181\n",
            "Epoch 8, Loss: 0.9077176859504298\n",
            "Epoch 9, Loss: 0.9090192819896498\n",
            "Epoch 10, Loss: 0.914704325952028\n",
            "Test Loss: 0.9220641016960144\n",
            "A3T-GCN model training and testing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from typing import List\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "from torch_geometric.nn import ChebConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "##########################################\n",
        "#        MODEL DEFINITION                #\n",
        "##########################################\n",
        "\n",
        "class TemporalGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, improved: bool = False,\n",
        "                 cached: bool = False, bias: bool = True):\n",
        "        super(TemporalGCN, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv_z = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.conv_r = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.conv_h = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.linear_z = nn.Linear(2 * out_channels, out_channels)\n",
        "        self.linear_r = nn.Linear(2 * out_channels, out_channels)\n",
        "        self.linear_h = nn.Linear(2 * out_channels, out_channels)\n",
        "\n",
        "    def _set_hidden_state(self, X, H):\n",
        "        if H is None:\n",
        "            H = torch.zeros(X.shape[0], X.shape[1], self.out_channels).to(X.device)\n",
        "        return H\n",
        "\n",
        "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
        "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], dim=2)\n",
        "        Z = self.linear_z(Z.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        Z = torch.sigmoid(Z)\n",
        "        return Z\n",
        "\n",
        "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
        "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], dim=2)\n",
        "        R = self.linear_r(R.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        R = torch.sigmoid(R)\n",
        "        return R\n",
        "\n",
        "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
        "        H_tilde = self.conv_h(X, edge_index, edge_weight)\n",
        "        H_tilde = torch.cat([H_tilde, H * R], dim=2)\n",
        "        H_tilde = self.linear_h(H_tilde.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        H_tilde = torch.tanh(H_tilde)\n",
        "        return H_tilde\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor,\n",
        "                edge_weight: torch.FloatTensor, H: torch.FloatTensor = None) -> torch.FloatTensor:\n",
        "        H = self._set_hidden_state(X, H)\n",
        "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
        "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
        "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
        "        H = Z * H + (1 - Z) * H_tilde\n",
        "        return H\n",
        "\n",
        "class TGCNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_nodes, edge_index, edge_weight):\n",
        "        super(TGCNModel, self).__init__()\n",
        "        self.tgcn = TemporalGCN(input_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.num_nodes = num_nodes\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_weight = edge_weight\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        \"\"\"\n",
        "        x: Tensor of shape (batch, T, N, F)\n",
        "        We'll iterate over the batch dimension.\n",
        "        Returns: prediction (batch, N) from the last time step.\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            xi = x[i]  # shape: (T, N, F)\n",
        "            if h is None:\n",
        "                hi = torch.zeros(xi.shape[0], self.num_nodes, self.hidden_dim, device=xi.device)\n",
        "            else:\n",
        "                hi = h[i]\n",
        "            out = self.tgcn(xi, self.edge_index, self.edge_weight, hi)  # out: (T, N, hidden_dim)\n",
        "            out = self.fc(out)  # out: (T, N, 1)\n",
        "            outputs.append(out)\n",
        "        outputs = torch.stack(outputs, dim=0)  # shape: (batch, T, N, 1)\n",
        "        # Return the prediction at the last time step for each node\n",
        "        return outputs[:, -1, :, 0], outputs\n",
        "\n",
        "##########################################\n",
        "#        DATA LOADING                    #\n",
        "##########################################\n",
        "\n",
        "class MontevideoBusDatasetLoader:\n",
        "    def __init__(self):\n",
        "        self._read_web_data()\n",
        "\n",
        "    def _read_web_data(self):\n",
        "        url = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/montevideo_bus.json\"\n",
        "        self._dataset = json.loads(urllib.request.urlopen(url).read())\n",
        "\n",
        "    def _get_node_ids(self):\n",
        "        return [node.get('bus_stop') for node in self._dataset[\"nodes\"]]\n",
        "\n",
        "    def _get_edges(self):\n",
        "        node_ids = self._get_node_ids()\n",
        "        node_id_map = dict(zip(node_ids, range(len(node_ids))))\n",
        "        edges = np.array(\n",
        "            [(node_id_map[d[\"source\"]], node_id_map[d[\"target\"]]) for d in self._dataset[\"links\"]]\n",
        "        ).T\n",
        "        return torch.tensor(edges, dtype=torch.long)\n",
        "\n",
        "    def _get_edge_weights(self):\n",
        "        self._edge_weights = np.array([d[\"weight\"] for d in self._dataset[\"links\"]])\n",
        "        return torch.tensor(self._edge_weights, dtype=torch.float)\n",
        "\n",
        "    def _get_features(self, feature_vars: List[str] = [\"y\"]):\n",
        "        features = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            X = node.get(\"X\")\n",
        "            for feature_var in feature_vars:\n",
        "                features.append(np.array(X.get(feature_var)))\n",
        "        # stacked_features shape: (T, num_nodes)\n",
        "        stacked_features = np.stack(features).T\n",
        "        standardized_features = (\n",
        "            stacked_features - np.mean(stacked_features, axis=0)\n",
        "        ) / np.std(stacked_features, axis=0)\n",
        "        # For each sliding window, each sample is of shape (num_nodes, lags)\n",
        "        self.features = [\n",
        "            standardized_features[i: i + self.lags, :].T\n",
        "            for i in range(len(stacked_features) - self.lags)\n",
        "        ]\n",
        "\n",
        "    def _get_targets(self, target_var: str = \"y\"):\n",
        "        targets = []\n",
        "        for node in self._dataset[\"nodes\"]:\n",
        "            y = node.get(target_var)\n",
        "            targets.append(np.array(y))\n",
        "        stacked_targets = np.stack(targets).T\n",
        "        standardized_targets = (\n",
        "            stacked_targets - np.mean(stacked_targets, axis=0)\n",
        "        ) / np.std(stacked_targets, axis=0)\n",
        "        # For each sliding window, the target is the next time step for each node.\n",
        "        self.targets = [\n",
        "            standardized_targets[i + self.lags, :]\n",
        "            for i in range(len(stacked_targets) - self.lags)\n",
        "        ]\n",
        "\n",
        "    def get_dataset(self, lags: int = 4, target_var: str = \"y\", feature_vars: List[str] = [\"y\"]):\n",
        "        self.lags = lags\n",
        "        edges = self._get_edges()\n",
        "        edge_weights = self._get_edge_weights()\n",
        "        self._get_features(feature_vars)\n",
        "        self._get_targets(target_var)\n",
        "        dataset = StaticGraphTemporalSignal(\n",
        "            edges, edge_weights, self.features, self.targets\n",
        "        )\n",
        "        return dataset\n",
        "\n",
        "##########################################\n",
        "#        TRAINING & TESTING              #\n",
        "##########################################\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            # X_batch shape: (batch, T, N, F)\n",
        "            y_pred, _ = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred, _ = model(X_batch)\n",
        "            predictions.append(y_pred)\n",
        "            targets.append(y_batch)\n",
        "    predictions = torch.cat(predictions, dim=0)\n",
        "    targets = torch.cat(targets, dim=0)\n",
        "    return predictions, targets\n",
        "\n",
        "##########################################\n",
        "#            MAIN SCRIPT                 #\n",
        "##########################################\n",
        "\n",
        "# Load dataset\n",
        "dataset_loader = MontevideoBusDatasetLoader()\n",
        "dataset = dataset_loader.get_dataset(lags=4)\n",
        "\n",
        "# The dataset provides a list of features (one per time window).\n",
        "num_time_steps = len(dataset.features)\n",
        "train_size = int(0.8 * num_time_steps)\n",
        "test_size = num_time_steps - train_size\n",
        "\n",
        "# --- Process features ---\n",
        "# Each element in dataset.features has shape: (num_nodes, lags)\n",
        "# We want to convert each sample to shape: (lags, num_nodes, 1)\n",
        "# First, stack the list into a NumPy array, then transpose and add the feature dimension.\n",
        "train_features_np = np.stack(dataset.features[:train_size], axis=0)  # shape: (train_samples, num_nodes, lags)\n",
        "train_features_np = np.transpose(train_features_np, (0, 2, 1))         # shape: (train_samples, lags, num_nodes)\n",
        "train_features_np = np.expand_dims(train_features_np, -1)               # shape: (train_samples, lags, num_nodes, 1)\n",
        "\n",
        "test_features_np = np.stack(dataset.features[train_size:], axis=0)      # shape: (test_samples, num_nodes, lags)\n",
        "test_features_np = np.transpose(test_features_np, (0, 2, 1))             # shape: (test_samples, lags, num_nodes)\n",
        "test_features_np = np.expand_dims(test_features_np, -1)                  # shape: (test_samples, lags, num_nodes, 1)\n",
        "\n",
        "# --- Process targets ---\n",
        "# Each element in dataset.targets has shape: (num_nodes,)\n",
        "train_targets_np = np.stack(dataset.targets[:train_size], axis=0)       # shape: (train_samples, num_nodes)\n",
        "test_targets_np = np.stack(dataset.targets[train_size:], axis=0)          # shape: (test_samples, num_nodes)\n",
        "\n",
        "# Convert to torch tensors (using np.stack avoids the warning)\n",
        "train_features_tensor = torch.tensor(train_features_np, dtype=torch.float)\n",
        "train_targets_tensor = torch.tensor(train_targets_np, dtype=torch.float)\n",
        "test_features_tensor = torch.tensor(test_features_np, dtype=torch.float)\n",
        "test_targets_tensor = torch.tensor(test_targets_np, dtype=torch.float)\n",
        "\n",
        "# Create DataLoader – here we use batch_size=1 so that each sample (a sliding window) is processed individually.\n",
        "batch_size = 1\n",
        "train_loader = DataLoader(TensorDataset(train_features_tensor, train_targets_tensor), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(test_features_tensor, test_targets_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Derive model dimensions:\n",
        "# - The feature dimension (F) is the last dimension (which is 1).\n",
        "# - The number of nodes (N) is the 3rd dimension (index 2) of our data.\n",
        "input_dim = train_features_tensor.shape[-1]  # should be 1\n",
        "num_nodes = train_features_tensor.shape[2]\n",
        "hidden_dim = 64\n",
        "edge_index = dataset.edge_index\n",
        "edge_weight = dataset.edge_weight\n",
        "\n",
        "# Initialize the model, criterion, and optimizer.\n",
        "model = TGCNModel(input_dim, hidden_dim, num_nodes, edge_index, edge_weight)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model.\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "# Test the model.\n",
        "predictions, targets = test_model(model, test_loader)\n",
        "\n",
        "# Compute the test loss.\n",
        "test_loss = criterion(predictions, targets)\n",
        "print(\"Test Loss:\", test_loss.item())\n",
        "\n",
        "print(\"Test Predictions:\", predictions)\n",
        "print(\"Test Targets:\", targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yByFVY8urkdE",
        "outputId": "f9d4e2ce-3efb-4b35-e8a7-8e57a2458e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "index 32 is out of bounds for dimension 0 with size 32",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-27f71a9500c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-27f71a9500c9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-27f71a9500c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgconvlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric_temporal/nn/recurrent/gconv_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, edge_index, edge_weight, H, C, lambda_max)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_cell_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_input_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_forget_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_cell_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric_temporal/nn/recurrent/gconv_lstm.py\u001b[0m in \u001b[0;36m_calculate_input_gate\u001b[0;34m(self, X, edge_index, edge_weight, H, C, lambda_max)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_input_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_x_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_h_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_c_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/cheb_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    149\u001b[0m     ) -> Tensor:\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         edge_index, norm = self.__norm__(\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/cheb_conv.py\u001b[0m in \u001b[0;36m__norm__\u001b[0;34m(self, edge_index, num_nodes, edge_weight, normalization, lambda_max, dtype, batch)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     ):\n\u001b[0;32m--> 119\u001b[0;31m         edge_index, edge_weight = get_laplacian(edge_index, edge_weight,\n\u001b[0m\u001b[1;32m    120\u001b[0m                                                 \u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                                 num_nodes)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/laplacian.py\u001b[0m in \u001b[0;36mget_laplacian\u001b[0;34m(edge_index, edge_weight, normalization, dtype, num_nodes)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: index 32 is out of bounds for dimension 0 with size 32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Working with the 2017 CitiBike dataset\n",
        "# Step 1: Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_scipy_sparse_matrix\n",
        "from tqdm import tqdm\n",
        "from os.path import join, isfile, exists\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Step 2: Define the CitiBikeDatasetInterface class\n",
        "class CitiBikeDatasetInterface:\n",
        "    \"\"\"\n",
        "    CitiBike dataset interface for processing and accessing 2017 CitiBike data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, url, num_timesteps_in=1, num_timesteps_out=1):\n",
        "        self.root = root\n",
        "        self.url = url\n",
        "        self.num_timesteps_in = num_timesteps_in\n",
        "        self.num_timesteps_out = num_timesteps_out\n",
        "        self.combined_csv_path = join(root, \"2017_combined_data.csv\")\n",
        "        self.data_path = join(root, \"2017-citibike-tripdata.zip\")\n",
        "\n",
        "        # Check if processed dataset exists; if not, download and process it\n",
        "        if not exists(self.combined_csv_path):  # Check if combined CSV exists\n",
        "            if not exists(self.data_path):  # Check if the zip file exists\n",
        "                self.download_and_extract()\n",
        "            self.combine_csv_files()\n",
        "\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "    def download_and_extract(self):\n",
        "        # Download the dataset from the provided URL\n",
        "        print(\"Downloading dataset...\")\n",
        "        response = requests.get(self.url, stream=True) # Download in chunks\n",
        "        total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024 #1 Kibibyte\n",
        "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "        with open(self.data_path, 'wb') as file:\n",
        "            for data in response.iter_content(block_size):\n",
        "                progress_bar.update(len(data))\n",
        "                file.write(data)\n",
        "        progress_bar.close()\n",
        "        if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
        "            print(\"ERROR, something went wrong\")\n",
        "\n",
        "        print(\"Dataset downloaded.\")\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.root)\n",
        "        print(\"Dataset extracted.\")\n",
        "\n",
        "\n",
        "    def combine_csv_files(self):\n",
        "        print(\"Combining monthly data into a single CSV...\")\n",
        "        all_files = []\n",
        "        # Updated to directly access the zip file\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            for file_info in zip_ref.infolist():\n",
        "                if file_info.filename.endswith(\".csv\"):\n",
        "                    file_info.filename = os.path.basename(file_info.filename)  # Remove path information\n",
        "                    zip_ref.extract(file_info, self.root)\n",
        "                    all_files.append(join(self.root, file_info.filename))\n",
        "\n",
        "        combined_df = pd.concat([pd.read_csv(f) for f in all_files], ignore_index=True)\n",
        "        combined_df.to_csv(self.combined_csv_path, index=False)\n",
        "        print(f\"Combined CSV saved to {self.combined_csv_path}\")\n",
        "\n",
        "    def load_data(self):\n",
        "        print(\"Loading data...\")\n",
        "        df = pd.read_csv(self.combined_csv_path)\n",
        "\n",
        "        # Example: Processing data into graph format\n",
        "        # Each node could represent a bike station, and edges represent trips between stations\n",
        "        self.node_features = torch.tensor(df.iloc[:, :5].values, dtype=torch.float)  # Example feature columns\n",
        "        self.targets = torch.tensor(df.iloc[:, 5].values, dtype=torch.float).unsqueeze(-1)  # Example target column\n",
        "\n",
        "        # Create a dummy edge index (in real scenarios, use actual graph structure)\n",
        "        num_nodes = self.node_features.shape[0]\n",
        "        self.edge_index = torch.tensor([[i, (i + 1) % num_nodes] for i in range(num_nodes)]).t().contiguous()\n",
        "\n",
        "    @property\n",
        "    def dim_node_features(self):\n",
        "        return self.node_features.shape[1]\n",
        "\n",
        "    @property\n",
        "    def dim_edge_features(self):\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def dim_target(self):\n",
        "        return self.targets.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.node_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return Data(\n",
        "            x=self.node_features[idx],\n",
        "            edge_index=self.edge_index,\n",
        "            y=self.targets[idx]\n",
        "        )\n",
        "\n",
        "\n",
        "# Step 3: Test the class in the same notebook\n",
        "# Define the root directory and dataset URL\n",
        "root = './data'\n",
        "url = 'https://s3.amazonaws.com/tripdata/2017-citibike-tripdata.zip'\n",
        "\n",
        "# Create an instance of the class\n",
        "dataset = CitiBikeDatasetInterface(root=root, url=url)\n",
        "\n",
        "# Print dataset details\n",
        "print(f\"Number of time steps: {len(dataset)}\")\n",
        "print(f\"Node feature dimension: {dataset.dim_node_features}\")\n",
        "print(f\"Edge feature dimension: {dataset.dim_edge_features}\")\n",
        "print(f\"Target dimension: {dataset.dim_target}\")\n",
        "\n",
        "# Access and inspect a single time step\n",
        "time_index = 0\n",
        "data = dataset[time_index]\n",
        "\n",
        "print(\"\\nExample Data Object:\")\n",
        "print(f\"Node Features (x):\\n{data.x}\")\n",
        "print(f\"Edge Index:\\n{data.edge_index}\")\n",
        "print(f\"Target (y):\\n{data.y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "NHWq795lMC1k",
        "outputId": "646f4647-c9f2-46a8-d46f-88d4a4b9f7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 557M/557M [00:16<00:00, 33.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded.\n",
            "Extracting dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1a20bbe053ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# Create an instance of the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCitiBikeDatasetInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Print dataset details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1a20bbe053ae>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, url, num_timesteps_in, num_timesteps_out)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_csv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if combined CSV exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if the zip file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_csv_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1a20bbe053ae>\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset extracted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "# CitiBike Dataset Interface\n",
        "class CitiBikeDatasetInterface:\n",
        "    def __init__(self, root, url, num_timesteps_in=4, num_timesteps_out=1):\n",
        "        self.root = root\n",
        "        self.url = url\n",
        "        self.num_timesteps_in = num_timesteps_in\n",
        "        self.num_timesteps_out = num_timesteps_out\n",
        "        self.combined_csv_path = os.path.join(root, \"2017_combined_data.csv\")\n",
        "        self.data_path = os.path.join(root, \"2017-citibike-tripdata.zip\")\n",
        "\n",
        "        if not os.path.exists(self.combined_csv_path):\n",
        "            if not os.path.exists(self.data_path):\n",
        "                self.download_and_extract()\n",
        "            self.combine_csv_files()\n",
        "\n",
        "    def download_and_extract(self):\n",
        "        print(\"Downloading dataset...\")\n",
        "        response = requests.get(self.url, stream=True)\n",
        "        with open(self.data_path, 'wb') as file:\n",
        "            for data in response.iter_content(1024):\n",
        "                file.write(data)\n",
        "        print(\"Dataset downloaded.\")\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.root)\n",
        "        print(\"Dataset extracted.\")\n",
        "\n",
        "    def combine_csv_files(self, chunksize=100000):\n",
        "        print(\"Combining monthly data into a single CSV...\")\n",
        "        all_files = []\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            for file_info in zip_ref.infolist():\n",
        "                if file_info.filename.endswith(\".csv\"):\n",
        "                    file_info.filename = os.path.basename(file_info.filename)\n",
        "                    zip_ref.extract(file_info, self.root)\n",
        "                    all_files.append(os.path.join(self.root, file_info.filename))\n",
        "\n",
        "        with open(self.combined_csv_path, 'w') as f_out:\n",
        "            for i, f in enumerate(all_files):\n",
        "                for chunk in pd.read_csv(f, chunksize=chunksize):\n",
        "                    chunk.to_csv(f_out, mode='a', index=False, header=(i == 0))\n",
        "\n",
        "        print(f\"Combined CSV saved to {self.combined_csv_path}\")\n",
        "\n",
        "    def load_and_process_data(self, chunksize=100000):\n",
        "        print(\"Processing data in chunks...\")\n",
        "        node_features = []\n",
        "        targets = []\n",
        "\n",
        "        for chunk in pd.read_csv(self.combined_csv_path, chunksize=chunksize):\n",
        "            chunk = chunk.sort_values(by=[\"starttime\"])\n",
        "            station_counts = chunk.groupby(\"start station id\").size().reset_index(name=\"trip_count\")\n",
        "\n",
        "            node_features.append(torch.tensor(station_counts[\"trip_count\"].values, dtype=torch.float32).unsqueeze(-1))\n",
        "            targets.append(node_features[-1].clone())\n",
        "\n",
        "        self.node_features = torch.cat(node_features, dim=0)\n",
        "        self.targets = torch.cat(targets, dim=0)\n",
        "\n",
        "        num_nodes = self.node_features.shape[0]\n",
        "        self.edge_index = torch.tensor([[i, (i + 1) % num_nodes] for i in range(num_nodes)]).t().contiguous()\n",
        "\n",
        "        # Free memory\n",
        "        del node_features, targets, chunk\n",
        "        gc.collect()\n",
        "\n",
        "    def get_dataset(self):\n",
        "        self.load_and_process_data()\n",
        "        dataset = CitiBikeDataset(self.node_features, self.targets, self.num_timesteps_in)\n",
        "        return dataset, self.edge_index\n",
        "\n",
        "\n",
        "# Memory-Efficient Dataset Class\n",
        "class CitiBikeDataset(Dataset):\n",
        "    def __init__(self, node_features, targets, num_timesteps_in):\n",
        "        self.node_features = node_features\n",
        "        self.targets = targets\n",
        "        self.num_timesteps_in = num_timesteps_in\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.node_features) - self.num_timesteps_in\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.node_features[idx: idx + self.num_timesteps_in]\n",
        "        y = self.targets[idx + self.num_timesteps_in]\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# A3T-GCN Model\n",
        "class A3TGCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_nodes):\n",
        "        super(A3TGCN, self).__init__()\n",
        "        self.gcn = nn.Linear(input_dim, hidden_dim)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=2, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_nodes, num_features = x.shape\n",
        "        x = x.view(-1, num_features)\n",
        "        x = self.gcn(x)\n",
        "        x = x.view(batch_size, num_nodes, -1)\n",
        "        x, _ = self.attention(x, x, x)\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "\n",
        "# Training and Testing\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_loader = CitiBikeDatasetInterface(root='./data', url='https://s3.amazonaws.com/tripdata/2017-citibike-tripdata.zip')\n",
        "    dataset, edge_index = dataset_loader.get_dataset()\n",
        "\n",
        "    # Set up DataLoader\n",
        "    batch_size = 32\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Model Setup\n",
        "    input_dim = dataset.node_features.shape[-1]\n",
        "    num_nodes = dataset.node_features.shape[0]\n",
        "    model = A3TGCN(input_dim=input_dim, hidden_dim=64, num_nodes=num_nodes)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "    # Testing Loop\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            test_loss += loss.item()\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader)}\")\n",
        "\n",
        "    # Free memory\n",
        "    del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()  # If using GPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZv-PtYUP2mQ",
        "outputId": "822cd5d2-ac19-4c1c-eef2-fb81cffdf85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data in chunks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-37ad7ce11fec>:124: DtypeWarning: Columns (1,2,4,8,12,16,17,19,23,27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  dataset, edge_index = dataset_loader.get_dataset()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 16138.324297542771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([11, 1])) that is different to the input size (torch.Size([11, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 15690.691955885406\n",
            "Epoch 3, Loss: 15263.56602483344\n",
            "Epoch 4, Loss: 15098.543139839838\n",
            "Epoch 5, Loss: 15036.339172575947\n",
            "Epoch 6, Loss: 15036.215854658067\n",
            "Epoch 7, Loss: 14994.234946752675\n",
            "Epoch 8, Loss: 15033.221074439924\n",
            "Epoch 9, Loss: 14989.938582470193\n",
            "Epoch 10, Loss: 14966.073861364703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([27, 1])) that is different to the input size (torch.Size([27, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 14880.922015359592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import requests\n",
        "import numpy as np\n",
        "from torch_geometric.nn import ChebConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "##########################################\n",
        "#      CitiBike Dataset Interface        #\n",
        "##########################################\n",
        "\n",
        "class CitiBikeDatasetInterface:\n",
        "    def __init__(self, root, url, num_timesteps_in=4, num_timesteps_out=1):\n",
        "        self.root = root\n",
        "        self.url = url\n",
        "        self.num_timesteps_in = num_timesteps_in\n",
        "        self.num_timesteps_out = num_timesteps_out\n",
        "        self.combined_csv_path = os.path.join(root, \"2017_combined_data.csv\")\n",
        "        self.data_path = os.path.join(root, \"2017-citibike-tripdata.zip\")\n",
        "\n",
        "        if not os.path.exists(self.combined_csv_path):\n",
        "            if not os.path.exists(self.data_path):\n",
        "                self.download_and_extract()\n",
        "            self.combine_csv_files()\n",
        "\n",
        "    def download_and_extract(self):\n",
        "        print(\"Downloading dataset...\")\n",
        "        response = requests.get(self.url, stream=True)\n",
        "        with open(self.data_path, 'wb') as file:\n",
        "            for data in response.iter_content(1024):\n",
        "                file.write(data)\n",
        "        print(\"Dataset downloaded.\")\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.root)\n",
        "        print(\"Dataset extracted.\")\n",
        "\n",
        "    def combine_csv_files(self, chunksize=100000):\n",
        "        print(\"Combining monthly data into a single CSV...\")\n",
        "        all_files = []\n",
        "        with zipfile.ZipFile(self.data_path, 'r') as zip_ref:\n",
        "            for file_info in zip_ref.infolist():\n",
        "                if file_info.filename.endswith(\".csv\"):\n",
        "                    file_info.filename = os.path.basename(file_info.filename)\n",
        "                    zip_ref.extract(file_info, self.root)\n",
        "                    all_files.append(os.path.join(self.root, file_info.filename))\n",
        "\n",
        "        with open(self.combined_csv_path, 'w') as f_out:\n",
        "            for i, f in enumerate(all_files):\n",
        "                for chunk in pd.read_csv(f, chunksize=chunksize):\n",
        "                    chunk.to_csv(f_out, mode='a', index=False, header=(i == 0))\n",
        "        print(f\"Combined CSV saved to {self.combined_csv_path}\")\n",
        "\n",
        "    def load_and_process_data(self, chunksize=100000):\n",
        "        print(\"Computing union of station IDs...\")\n",
        "        # First pass: compute the union of all station IDs.\n",
        "        station_id_set = set()\n",
        "        for chunk in pd.read_csv(self.combined_csv_path, chunksize=chunksize, usecols=[\"start station id\"]):\n",
        "            # Convert station IDs to string to ensure consistent type.\n",
        "            chunk[\"start station id\"] = chunk[\"start station id\"].astype(str)\n",
        "            station_id_set.update(chunk[\"start station id\"].unique())\n",
        "        station_ids = sorted(list(station_id_set))\n",
        "        self.station_ids = station_ids\n",
        "        num_stations = len(station_ids)\n",
        "        print(f\"Found {num_stations} unique station IDs.\")\n",
        "\n",
        "        # Create a mapping from station id (as string) to index.\n",
        "        station_id_map = {station_id: idx for idx, station_id in enumerate(station_ids)}\n",
        "\n",
        "        print(\"Processing data in chunks...\")\n",
        "        node_features = []\n",
        "        targets = []\n",
        "        for chunk in pd.read_csv(self.combined_csv_path, chunksize=chunksize):\n",
        "            # Ensure station IDs are strings.\n",
        "            chunk[\"start station id\"] = chunk[\"start station id\"].astype(str)\n",
        "            # Sort by time so that our sliding window is in order.\n",
        "            chunk = chunk.sort_values(by=[\"starttime\"])\n",
        "            # Group by station id to get trip counts.\n",
        "            station_counts = chunk.groupby(\"start station id\").size().reset_index(name=\"trip_count\")\n",
        "            # Create a numpy array of zeros with length = num_stations.\n",
        "            arr = np.zeros(num_stations, dtype=np.float32)\n",
        "            # Fill in the counts for the stations present in this chunk.\n",
        "            for _, row in station_counts.iterrows():\n",
        "                station_id = row[\"start station id\"]\n",
        "                count = row[\"trip_count\"]\n",
        "                # Use the mapping to determine the correct index.\n",
        "                idx = station_id_map[station_id]\n",
        "                arr[idx] = count\n",
        "            # Convert to tensor and shape becomes (num_stations, 1)\n",
        "            ts = torch.tensor(arr, dtype=torch.float32).unsqueeze(-1)\n",
        "            node_features.append(ts)\n",
        "            targets.append(ts.clone())\n",
        "        # Stack along a new (time) dimension: shape = (T, num_stations, 1)\n",
        "        self.node_features = torch.stack(node_features, dim=0)\n",
        "        self.targets = torch.stack(targets, dim=0)\n",
        "\n",
        "        # Create a simple ring (cycle) over nodes.\n",
        "        self.edge_index = torch.tensor(\n",
        "            [[i, (i + 1) % num_stations] for i in range(num_stations)]\n",
        "        ).t().contiguous()\n",
        "\n",
        "\n",
        "    def get_dataset(self):\n",
        "        self.load_and_process_data()\n",
        "        dataset = CitiBikeDataset(self.node_features, self.targets, self.num_timesteps_in)\n",
        "        return dataset, self.edge_index\n",
        "\n",
        "##########################################\n",
        "#         CitiBike Dataset Class         #\n",
        "##########################################\n",
        "\n",
        "class CitiBikeDataset(Dataset):\n",
        "    def __init__(self, node_features, targets, num_timesteps_in):\n",
        "        \"\"\"\n",
        "        node_features: Tensor of shape (T, N, F)\n",
        "        targets: Tensor of shape (T, N, F)\n",
        "        \"\"\"\n",
        "        self.node_features = node_features\n",
        "        self.targets = targets\n",
        "        self.num_timesteps_in = num_timesteps_in\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of sliding windows available\n",
        "        return self.node_features.shape[0] - self.num_timesteps_in\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # x: window of past time steps, shape: (num_timesteps_in, N, F)\n",
        "        # y: next time step target, shape: (N, F)\n",
        "        x = self.node_features[idx: idx + self.num_timesteps_in]\n",
        "        y = self.targets[idx + self.num_timesteps_in]\n",
        "        # Squeeze the last dimension of y so that it is (N)\n",
        "        return x, y.squeeze(-1)\n",
        "\n",
        "##########################################\n",
        "#       TemporalGCN & TGCNModel          #\n",
        "##########################################\n",
        "\n",
        "class TemporalGCN(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, improved: bool = False,\n",
        "                 cached: bool = False, bias: bool = True):\n",
        "        super(TemporalGCN, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.conv_z = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.conv_r = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.conv_h = ChebConv(in_channels, out_channels, K=2, bias=bias)\n",
        "        self.linear_z = nn.Linear(2 * out_channels, out_channels)\n",
        "        self.linear_r = nn.Linear(2 * out_channels, out_channels)\n",
        "        self.linear_h = nn.Linear(2 * out_channels, out_channels)\n",
        "\n",
        "    def _set_hidden_state(self, X, H):\n",
        "        if H is None:\n",
        "            H = torch.zeros(X.shape[0], X.shape[1], self.out_channels, device=X.device)\n",
        "        return H\n",
        "\n",
        "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
        "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], dim=2)\n",
        "        Z = self.linear_z(Z.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        Z = torch.sigmoid(Z)\n",
        "        return Z\n",
        "\n",
        "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
        "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], dim=2)\n",
        "        R = self.linear_r(R.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        R = torch.sigmoid(R)\n",
        "        return R\n",
        "\n",
        "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
        "        H_tilde = self.conv_h(X, edge_index, edge_weight)\n",
        "        H_tilde = torch.cat([H_tilde, H * R], dim=2)\n",
        "        H_tilde = self.linear_h(H_tilde.reshape(-1, 2 * self.out_channels)).reshape(X.shape[0], X.shape[1], self.out_channels)\n",
        "        H_tilde = torch.tanh(H_tilde)\n",
        "        return H_tilde\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor,\n",
        "                edge_weight: torch.FloatTensor, H: torch.FloatTensor = None) -> torch.FloatTensor:\n",
        "        H = self._set_hidden_state(X, H)\n",
        "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
        "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
        "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
        "        H = Z * H + (1 - Z) * H_tilde\n",
        "        return H\n",
        "\n",
        "class TGCNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_nodes, edge_index, edge_weight):\n",
        "        super(TGCNModel, self).__init__()\n",
        "        self.tgcn = TemporalGCN(input_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.num_nodes = num_nodes\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_weight = edge_weight\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        \"\"\"\n",
        "        x: Tensor of shape (batch, T, N, F)\n",
        "        Returns: predictions for the last time step, shape: (batch, N)\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            xi = x[i]  # shape: (T, N, F)\n",
        "            if h is None:\n",
        "                hi = torch.zeros(xi.shape[0], self.num_nodes, self.hidden_dim, device=xi.device)\n",
        "            else:\n",
        "                hi = h[i]\n",
        "            out = self.tgcn(xi, self.edge_index, self.edge_weight, hi)  # (T, N, hidden_dim)\n",
        "            out = self.fc(out)  # (T, N, 1)\n",
        "            outputs.append(out)\n",
        "        outputs = torch.stack(outputs, dim=0)  # (batch, T, N, 1)\n",
        "        return outputs[:, -1, :, 0], outputs  # return predictions from the last time step\n",
        "\n",
        "##########################################\n",
        "#         Training & Testing             #\n",
        "##########################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup paths and parameters\n",
        "    root = './data'\n",
        "    url = 'https://s3.amazonaws.com/tripdata/2017-citibike-tripdata.zip'\n",
        "    num_timesteps_in = 4  # window length for input\n",
        "    num_timesteps_out = 1\n",
        "\n",
        "    # Get the dataset and edge_index from the CitiBike interface.\n",
        "    dataset_interface = CitiBikeDatasetInterface(root, url, num_timesteps_in, num_timesteps_out)\n",
        "    dataset_raw, edge_index = dataset_interface.get_dataset()\n",
        "\n",
        "    # Here, node_features now has shape (T, N, F); determine number of nodes from dimension 1.\n",
        "    num_nodes = dataset_interface.node_features.shape[1]\n",
        "\n",
        "    # The CitiBikeDataset is a sliding-window over the time axis.\n",
        "    dataset = dataset_raw\n",
        "\n",
        "    # Split dataset into training and testing parts.\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # Create DataLoaders (batch size 32)\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Model Setup:\n",
        "    # - Input dimension F is the last dimension of node_features (should be 1).\n",
        "    input_dim = dataset_interface.node_features.shape[-1]\n",
        "    hidden_dim = 64\n",
        "    # For edge_weight, we simply assign ones (one weight per edge).\n",
        "    edge_weight = torch.ones(edge_index.shape[1], dtype=torch.float)\n",
        "\n",
        "    model = TGCNModel(input_dim, hidden_dim, num_nodes, edge_index, edge_weight)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            # X_batch: shape (batch, num_timesteps_in, N, F)\n",
        "            # y_batch: shape (batch, N)\n",
        "            y_pred, _ = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Testing Loop\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred, _ = model(X_batch.float())\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            test_loss += loss.item()\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
        "\n",
        "    # Free memory\n",
        "    del dataset, train_dataset, test_dataset, train_loader, test_loader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "fjBU-wHGT_dN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}